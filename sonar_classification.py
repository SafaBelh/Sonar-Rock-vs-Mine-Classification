# -*- coding: utf-8 -*-
"""PROJECT1_SONAR_ROCK_VS_MINE_PREDICTION .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Mv4s36_jMpitXrTupEVJeuSZNPKwC7Qu

üí° Project Overview

```
# Sonar Rock vs Mine Classification

## Objective
Build a Machine Learning model that classifies sonar signals as :
- Rock (R)
- Mine (M)

## Dataset
- 60 numerical features (sonar energy measurements)
- 1 target column (R or M)

## Algorithm Used
Logistic Regression (Binary Classification)

```
1Ô∏è‚É£ Import Dependencies
"""

# ===============================
# 1. Import Required Libraries
# ===============================

# Numerical operations
import numpy as np

# Data manipulation
import pandas as pd

# Splitting dataset into training and testing sets
from sklearn.model_selection import train_test_split

# Logistic Regression model
from sklearn.linear_model import LogisticRegression

# Evaluation metrics
from sklearn.metrics import accuracy_score, confusion_matrix

# Feature scaling (important for Logistic Regression)
from sklearn.preprocessing import StandardScaler

"""2Ô∏è‚É£ Load the Dataset"""

# ===============================
# 2. Load Dataset
# ===============================

# Load the sonar dataset
# header=None because the dataset does not contain column names
sonar_data = pd.read_csv('data/sonar_data.csv', header=None)

# Display first 5 rows
sonar_data.head()

"""3Ô∏è‚É£ Basic Data Exploration"""

# ===============================
# 3. Exploratory Data Analysis
# ===============================

# Check dataset shape (rows, columns)
print("Dataset Shape:", sonar_data.shape)

# Statistical summary of numerical features
sonar_data.describe()

# Check class distribution
print("\nClass Distribution:")
print(sonar_data[60].value_counts())

"""4Ô∏è‚É£ Separate Features and Target"""

# ===============================
# 4. Separate Features and Labels
# ===============================

# X ‚Üí input features (first 60 columns)
X = sonar_data.drop(columns=60)

# Y ‚Üí target variable (Rock or Mine)
Y = sonar_data[60]

print("Feature Shape:", X.shape)
print("Label Shape:", Y.shape)


"""5Ô∏è‚É£ Train-Test Split"""

# ===============================
# 5. Split Data into Train and Test Sets
# ===============================

X_train, X_test, Y_train, Y_test = train_test_split(
    X,
    Y,
    test_size=0.1,       # 10% for testing
    stratify=Y,          # Maintain same class ratio
    random_state=1       # Reproducibility
)

print("Training Shape:", X_train.shape)
print("Testing Shape:", X_test.shape)

""" 6Ô∏è‚É£ Model Training"""

# ===============================
# 6. Model Training
# ===============================

# Initialize Logistic Regression model
model = LogisticRegression()

# Train the model using training data
model.fit(X_train, Y_train)

print("Model training completed.")

""" 7Ô∏è‚É£ Model Evaluation"""

# ===============================
# 7. Model Evaluation
# ===============================

# Predictions on training data
train_predictions = model.predict(X_train)
training_accuracy = accuracy_score(Y_train, train_predictions)

# Predictions on test data
test_predictions = model.predict(X_test)
test_accuracy = accuracy_score(Y_test, test_predictions)

print("Training Accuracy:", training_accuracy)
print("Test Accuracy:", test_accuracy)

""" 8Ô∏è‚É£ Confusion Matrix"""

# ===============================
# 8. Confusion Matrix
# ===============================

cm = confusion_matrix(Y_test, test_predictions)

print("Confusion Matrix:")
print(cm)

""" 9Ô∏è‚É£ Predict New Data"""

# ===============================
# 9. Making a Prediction
# ===============================

# Example input (60 features)
input_data = (0.0307,0.0523,0.0653,0.0521,0.0611,0.0577,0.0665,0.0664,
              0.1460,0.2792,0.3877,0.4992,0.4981,0.4972,0.5607,0.7339,
              0.8230,0.9173,0.9975,0.9911,0.8240,0.6498,0.5980,0.4862,
              0.3150,0.1543,0.0989,0.0284,0.1008,0.2636,0.2694,0.2930,
              0.2925,0.3998,0.3660,0.3172,0.4609,0.4374,0.1820,0.3376,
              0.6202,0.4448,0.1863,0.1420,0.0589,0.0576,0.0672,0.0269,
              0.0245,0.0190,0.0063,0.0321,0.0189,0.0137,0.0277,0.0152,
              0.0052,0.0121,0.0124,0.0055)

# Convert to numpy array
input_data_np = np.asarray(input_data)

# Reshape to match model input format (1 sample, 60 features)
input_data_reshaped = input_data_np.reshape(1, -1)

# Make prediction
prediction = model.predict(input_data_reshaped)

if prediction[0] == 'R':
    print("The object is a Rock")
else:
    print("The object is a Mine")